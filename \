#include "external/cglm/include/cglm/types.h"
#include "tinytypes.h"
#include "vk_defaults.h"
#include "vk_startup.h"
#include "vk_swapchain.h"
#include "vk_queue.h"
#include "vk_sync.h"
#include "vk_barrier.h"
#include "vk_cmd.h"
#include "vk_pipelines.h"
#include "vk_resources.h"
#include "bindlesstextures.h"
#include "proceduraltextures.h"
#include "desc_write.h"
#include "debugtext.h"
#include "gpu_timer.h"
#include <stdbool.h>
#include <stdint.h>
#include <time.h>
#include <math.h>
#include <vulkan/vulkan_core.h>
#include "depth.h"
#include "camera.h"
#include "scene.h"
typedef uint32_t MeshID;
typedef uint32_t MaterialID;
typedef uint32_t TextureID;
typedef uint32_t ObjectID;

static bool g_framebuffer_resized = false;

static void framebuffer_resize_callback(GLFWwindow* window, int width, int height)
{
    (void)window;
    (void)width;
    (void)height;
    g_framebuffer_resized = true;
}
typedef struct GpuMeshBuffers
{
    Buffer vertex;
    Buffer index;

    uint32_t index_count;
    uint32_t vertex_count;
} GpuMeshBuffers;

typedef struct GlobalUBO
{
    mat4 view;
    mat4 proj;
    mat4 viewproj;
    vec4 cameraPos;
} GlobalUBO;
typedef struct RaymarchUBO
{
    float resolution[2];
    float time;
    float pad;
} RaymarchUBO;


typedef struct
{
    VkSemaphore image_available_semaphore;
    VkFence     in_flight_fence;
} FrameSync;

typedef struct Vertex
{
    float pos[2];
    float col[3];
} Vertex;


typedef struct InstanceData
{
    float pos[3];
    float rot[4];  // quat (x,y,z,w)
    float scale;
} InstanceData;
typedef struct MeshDrawCommand
{
    uint32_t drawId;
} MeshDrawCommand;

typedef struct MeshDrawGpu
{
    float    position_scale[4];
    float    orientation[4];
    uint32_t meshIndex;
    uint32_t postPass;
    uint32_t materialIndex;
    uint32_t pad;
} MeshDrawGpu;

typedef struct MeshLodGpu
{
    uint32_t indexOffset;
    uint32_t indexCount;
    float    error;
    float    pad;
} MeshLodGpu;

typedef struct MeshGpu
{
    float      center_radius[4];
    uint32_t   vertexOffset;
    uint32_t   vertexCount;
    uint32_t   lodCount;
    uint32_t   pad;
    MeshLodGpu lods[SCENE_MAX_LODS];
} MeshGpu;

typedef struct CullDataGpu
{
    mat4     view;
    vec4     frustum;    // x=1, y=tanHalfX, z=1, w=tanHalfY
    vec4     params;     // x=znear, y=zfar, z=lodTargetPx, w=viewportHeight
    uint32_t counts[4];  // x=drawCount, y=lodEnabled
} CullDataGpu;

typedef struct MaterialGpu
{
    uint32_t textures[4];
    float    diffuseFactor[4];
    float    specularFactor[4];
    float    emissiveFactor[4];
} MaterialGpu;

typedef struct GpuStats
{
    float frame_us;
    float gfx_us;
    float text_us;
} GpuStats;

static const Vertex TRIANGLE_VERTS[] = {
    {{0.0f, -0.5f}, {1.0f, 0.0f, 0.0f}},
    {{0.5f, 0.5f}, {0.0f, 1.0f, 0.0f}},
    {{-0.5f, 0.5f}, {0.0f, 0.0f, 1.0f}},
};


static void build_global_ubo(GlobalUBO* ubo, Camera* cam, float aspect)
{
    camera_build_view(ubo->view, cam);
    camera_build_proj(ubo->proj, cam, aspect);

    // Vulkan clip fix (Y flip)
    ubo->proj[1][1] *= -1.0f;

    glm_mat4_mul(ubo->proj, ubo->view, ubo->viewproj);

    glm_vec3_copy(cam->position, ubo->cameraPos);
    ubo->cameraPos[3] = 1.0f;
}


int main()
{


    // ============================================================
    // Platform / Window
    // ============================================================
    VK_CHECK(volkInitialize());

    if(!is_instance_extension_supported("VK_KHR_wayland_surface"))
        glfwInitHint(GLFW_PLATFORM, GLFW_PLATFORM_X11);
    else
        glfwInitHint(GLFW_PLATFORM, GLFW_PLATFORM_WAYLAND);

    assert(glfwInit());

    glfwWindowHint(GLFW_CLIENT_API, GLFW_NO_API);
    GLFWwindow* window = glfwCreateWindow(800, 600, "Vulkan", NULL, NULL);


    glfwSetFramebufferSizeCallback(window, framebuffer_resize_callback);
    // ============================================================
    // Instance / Device setup
    // ============================================================
    const char* dev_exts[] = {VK_KHR_SWAPCHAIN_EXTENSION_NAME};

    u32          glfw_ext_count = 0;
    const char** glfw_exts      = glfwGetRequiredInstanceExtensions(&glfw_ext_count);


    renderer_context_desc desc = {
        .app_name = "My Renderer",

        .instance_layers     = NULL,
        .instance_extensions = glfw_exts,
        .device_extensions   = dev_exts,

        .instance_layer_count        = 0,
        .instance_extension_count    = glfw_ext_count,
        .device_extension_count      = 1,
        .enable_gpu_based_validation = true,
        .enable_validation           = true,

        .validation_severity = VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_SEVERITY_INFO_BIT_EXT
                               | VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT,
        .validation_types = VK_DEBUG_UTILS_MESSAGE_TYPE_GENERAL_BIT_EXT | VK_DEBUG_UTILS_MESSAGE_TYPE_VALIDATION_BIT_EXT
                            | VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT,
        .use_custom_features = false  // IMPORTANT
    };


    VkDescriptorPool persistent_pool;
    VkDescriptorPool frame_pools[MAX_FRAME_IN_FLIGHT];
    VkCommandPool    upload_pool;
    renderer_context ctx = {0};
    vk_create_instance(&ctx, &desc);
    volkLoadInstanceOnly(ctx.instance);
    setup_debug_messenger(&ctx, &desc);

    VkSurfaceKHR surface;
    VK_CHECK(glfwCreateWindowSurface(ctx.instance, window, NULL, &surface));

    VkPhysicalDevice gpu = pick_physical_device(ctx.instance, surface, &desc);


    queue_families qf = {0};
    find_queue_families(gpu, surface, &qf);

    VkDevice device = VK_NULL_HANDLE;
    create_device(gpu, surface, &desc, qf, &device);
    volkLoadDevice(device);
    init_device_queues(device, &qf);


    ResourceAllocator allocator = {0};

    VmaAllocatorCreateInfo vmaInfo = {
        .physicalDevice = gpu,
        .device         = device,
        .instance       = ctx.instance,
    };
    res_init(ctx.instance, device, gpu, &allocator, vmaInfo);
    // ============================================================
    // Per-frame sync + command buffers
    // ============================================================
    u32             current_frame = 0;
    u32             image_index   = 0;
    FrameSync       frame_sync[MAX_FRAME_IN_FLIGHT];
    VkCommandPool   cmd_pools[MAX_FRAME_IN_FLIGHT];
    VkCommandBuffer cmd_buffers[MAX_FRAME_IN_FLIGHT];
    forEach(i, MAX_FRAME_IN_FLIGHT)
    {
        vk_create_semaphore(device, &frame_sync[i].image_available_semaphore);
        vk_create_fence(device, true, &frame_sync[i].in_flight_fence);
    };
    vk_cmd_create_many_pools(device, qf.graphics_family, true, false, MAX_FRAME_IN_FLIGHT, cmd_pools);
    forEach(i, MAX_FRAME_IN_FLIGHT)
    {
        vk_cmd_alloc(device, cmd_pools[i], true, &cmd_buffers[i]);
    }

    vk_cmd_create_pool(device, qf.graphics_family, false, true, &upload_pool);

    FlowSwapchain swap = {0};

    int fb_w = 0, fb_h = 0;
    glfwGetFramebufferSize(window, &fb_w, &fb_h);

    FlowSwapchainCreateInfo sci = {.surface         = surface,
                                   .width           = fb_w,
                                   .height          = fb_h,
                                   .min_image_count = 3,
                                   //        .preferred_present_mode = vk_swapchain_select_present_mode(gpu, surface, false),
                                   .preferred_present_mode = VK_PRESENT_MODE_IMMEDIATE_KHR,
                                   .preferred_format       = VK_FORMAT_B8G8R8A8_UNORM,
                                   .preferred_color_space  = VK_COLOR_SPACE_SRGB_NONLINEAR_KHR,
                                   .extra_usage   = VK_IMAGE_USAGE_TRANSFER_DST_BIT | VK_IMAGE_USAGE_STORAGE_BIT,
                                   .old_swapchain = VK_NULL_HANDLE};

    vk_create_swapchain(device, gpu, &swap, &sci, qf.graphics_queue, upload_pool);


    DepthTarget depth;
    VkFormat    depth_format = pick_depth_format(gpu);
    assert(depth_format != VK_FORMAT_UNDEFINED);
    create_depth_target(&allocator, &depth, swap.extent.width, swap.extent.height, depth_format);

    PipelineLayoutCache pipe_cache = {0};
    pipeline_layout_cache_init(&pipe_cache);

    DescriptorLayoutCache desc_cache = {0};
    descriptor_layout_cache_init(&desc_cache, device);

    DescriptorAllocator persistent_desc = {0};
    descriptor_allocator_init(&persistent_desc, device, false);

    DescriptorAllocator bindless_desc = {0};
    descriptor_allocator_init(&bindless_desc, device, true);  // bindless needs update-after-bind

    BindlessTextures bindless = {0};
    bindless_textures_init(&bindless, device, &bindless_desc, &desc_cache, MAX_BINDLESS_TEXTURES);

    // -------------------------------------------------------------
    // Procedural bindless textures
    // -------------------------------------------------------------
    const uint32_t tex_w      = 256;
    const uint32_t tex_h      = 256;
    size_t         tex_size   = (size_t)tex_w * (size_t)tex_h * 4u;
    uint8_t*       tex_pixels = (uint8_t*)malloc(tex_size);

    TextureResource tex_dummy    = {0};
    TextureResource tex_checker  = {0};
    TextureResource tex_gradient = {0};

    uint32_t checker_slot  = bindless_textures_alloc_slot(&bindless);
    uint32_t gradient_slot = bindless_textures_alloc_slot(&bindless);

    if(checker_slot == 0 || gradient_slot == 0)
    {
        log_error("Bindless texture slots exhausted");
        return 1;
    }

    // dummy slot 0 (solid white)
    procedural_fill_solid_rgba8(tex_pixels, 1, 1, 255, 255, 255, 255);
    bindless_textures_create_rgba8(&allocator, device, qf.graphics_queue, upload_pool, 1, 1, tex_pixels, &tex_dummy);
    tex_dummy.bindless_index = 0;
    bindless.textures[0]     = tex_dummy;
    bindless_textures_write(&bindless, device, 0, tex_dummy.view, tex_dummy.sampler, VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL);

    procedural_fill_checker_rgba8(tex_pixels, tex_w, tex_h, 16, 32, 32, 32, 220, 220, 220);
    bindless_textures_create_rgba8(&allocator, device, qf.graphics_queue, upload_pool, tex_w, tex_h, tex_pixels, &tex_checker);
    tex_checker.bindless_index      = checker_slot;
    bindless.textures[checker_slot] = tex_checker;
    bindless_textures_write(&bindless, device, checker_slot, tex_checker.view, tex_checker.sampler,
                            VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL);

    procedural_fill_gradient_rgba8(tex_pixels, tex_w, tex_h);
    bindless_textures_create_rgba8(&allocator, device, qf.graphics_queue, upload_pool, tex_w, tex_h, tex_pixels, &tex_gradient);
    tex_gradient.bindless_index      = gradient_slot;
    bindless.textures[gradient_slot] = tex_gradient;
    bindless_textures_write(&bindless, device, gradient_slot, tex_gradient.view, tex_gradient.sampler,
                            VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL);

    free(tex_pixels);

    VkDebugText dbg = {0};
    vk_debug_text_init(&dbg, device, &persistent_desc, &desc_cache, &pipe_cache, &swap, "compiledshaders/debug_text.comp.spv");


    GraphicsPipelineConfig cfg = graphics_pipeline_config_default();
    cfg.color_attachment_count = 1;
    cfg.color_formats          = &swap.format;
    cfg.depth_format           = depth_format;

    cfg.depth_test_enable  = true;
    cfg.depth_write_enable = true;

    VkPipelineLayout pipeline_layout = VK_NULL_HANDLE;

    VkDescriptorSetLayoutBinding set0_bindings[5] = {
        {
            .binding         = 0,
            .descriptorType  = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,
            .descriptorCount = 1,
            .stageFlags      = VK_SHADER_STAGE_VERTEX_BIT,
        },
        {
            .binding         = 1,
            .descriptorType  = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,
            .descriptorCount = 1,
            .stageFlags      = VK_SHADER_STAGE_VERTEX_BIT,
        },
        {
            .binding         = 2,
            .descriptorType  = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,
            .descriptorCount = 1,
            .stageFlags      = VK_SHADER_STAGE_VERTEX_BIT,
        },
        {
            .binding         = 3,
            .descriptorType  = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER,
            .descriptorCount = 1,
            .stageFlags      = VK_SHADER_STAGE_VERTEX_BIT,
        },
        {
            .binding         = 4,
            .descriptorType  = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,
            .descriptorCount = 1,
            .stageFlags      = VK_SHADER_STAGE_FRAGMENT_BIT,
        },
    };

    VkDescriptorSetLayoutCreateInfo set0_layout_info = {
        .sType        = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO,
        .bindingCount = 5,
        .pBindings    = set0_bindings,
    };

    VkDescriptorSetLayout set0_layout    = get_or_create_set_layout(&desc_cache, set0_bindings, 5, 0, NULL);
    VkDescriptorSetLayout set_layouts[2] = {set0_layout, bindless.layout};
    pipeline_layout                      = pipeline_layout_cache_get(device, &pipe_cache, set_layouts, 2, NULL, 0);

    VkPipeline pipeline = create_graphics_pipeline(device, VK_NULL_HANDLE, &desc_cache, &pipe_cache, "compiledshaders/tri.vert.spv",
                                                   "compiledshaders/tri.frag.spv", &cfg, pipeline_layout, &pipeline_layout);

    VkPipelineLayout cull_layout   = VK_NULL_HANDLE;
    VkPipeline       cull_pipeline = create_compute_pipeline(device, VK_NULL_HANDLE, &desc_cache, &pipe_cache,
                                                             "compiledshaders/cull.comp.spv", &cull_layout);


    GraphicsPipelineConfig rayCfg = graphics_pipeline_config_default();
    rayCfg.color_attachment_count = 1;
    rayCfg.color_formats          = &swap.format;
    rayCfg.depth_test_enable      = false;
    rayCfg.depth_write_enable     = false;
    rayCfg.depth_format           = VK_FORMAT_UNDEFINED;  // or keep but disable test/write
    rayCfg.use_vertex_input       = false;                // i
    rayCfg.blend_enable           = true;                 // IMPORTANT
    VkPipelineLayout raymarch_layout;

    VkPipeline raymarch_pipeline =
        create_graphics_pipeline(device, NULL, &desc_cache, &pipe_cache, "compiledshaders/fullscreen.vert.spv",
                                 "compiledshaders/fullscreen.frag.spv", &rayCfg, VK_NULL_HANDLE, &raymarch_layout);
    Buffer global_ubo_buf    = {0};
    Buffer material_buffer   = {0};
    Buffer cull_data_buffer  = {0};
    Buffer mesh_buffer       = {0};
    Buffer draw_count_buffer = {0};
    Buffer raymarch_ubo      = {0};
    res_create_buffer(&allocator, sizeof(RaymarchUBO), VK_BUFFER_USAGE_2_UNIFORM_BUFFER_BIT, VMA_MEMORY_USAGE_AUTO_PREFER_HOST,
                      VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_MAPPED_BIT, 0, &raymarch_ubo);

    res_create_buffer(&allocator, sizeof(GlobalUBO), VK_BUFFER_USAGE_2_UNIFORM_BUFFER_BIT, VMA_MEMORY_USAGE_AUTO_PREFER_HOST,
                      VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_MAPPED_BIT, 0, &global_ubo_buf);

    res_create_buffer(&allocator, sizeof(CullDataGpu), VK_BUFFER_USAGE_2_UNIFORM_BUFFER_BIT, VMA_MEMORY_USAGE_AUTO_PREFER_HOST,
                      VMA_ALLOCATION_CREATE_HOST_ACCESS_SEQUENTIAL_WRITE_BIT | VMA_ALLOCATION_CREATE_MAPPED_BIT, 0,
                      &cull_data_buffer);

    VkDescriptorSetLayoutBinding rayBind       = {.binding         = 0,
                                                  .descriptorType  = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER,
                                                  .descriptorCount = 1,
                                                  .stageFlags      = VK_SHADER_STAGE_FRAGMENT_BIT};
    VkDescriptorSetLayoutCreateInfo rayLayoutInfo = {
        .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO, .bindingCount = 1, .pBindings = &rayBind};

    VkDescriptorSet  raySet = VK_NULL_HANDLE;

    VkDescriptorSet set0 = VK_NULL_HANDLE;

    GpuProfiler prof[MAX_FRAME_IN_FLIGHT];
    GpuStats    stats[MAX_FRAME_IN_FLIGHT] = {0};

    for(u32 i = 0; i < MAX_FRAME_IN_FLIGHT; i++)
    {
        if(!gpu_prof_init(&prof[i], device, gpu, 256))
        {
            printf("gpu_prof_init failed\n");
            return 1;
        }
    }

    Scene scene = {0};
    typedef struct SceneEntry
    {
        const char* path;
        const char* label;
        vec3        pos;
        float       scale;
    } SceneEntry;

    SceneEntry entries[] = {

        {"/home/lk/myprojects/flow14/data/cow.glb", "Cow", {0.0f, 0.0f, 0.0f}, 1.0f},

        {"/home/lk/myprojects/flow14/data/cow.glb", "Cow", {8.0f, 0.0f, 0.0f}, 1.0f},

        {"/home/lk/myprojects/flow14/data/cow.glb", "Cow", {16.0f, 0.0f, 0.0f}, 1.0f},

        {"/home/lk/myprojects/flow14/data/cow.glb", "Cow", {24.0f, 0.0f, 0.0f}, 1.0f},

        {"/home/lk/myprojects/flow14/data/cow.glb", "Cow", {0.0f, 8.0f, 0.0f}, 1.0f},

        {"/home/lk/myprojects/flow14/data/cow.glb", "Cow", {8.0f, 16.0f, 0.0f}, 1.0f},

        {"/home/lk/myprojects/flow14/data/cow.glb", "Cow", {16.0f, 24.0f, 0.0f}, 1.0f},

        {"/home/lk/myprojects/flow14/data/cow.glb", "Cow", {24.0f, 32.0f, 0.0f}, 1.0f},
    };


    uint32_t entry_count              = (uint32_t)(sizeof(entries) / sizeof(entries[0]));
    uint32_t gltf_draw_template_count = 0;


    for(uint32_t i = 0; i < entry_count; i++)
    {
        versor rot;
        glm_quat_identity(rot);

        if(!scene_load_gltf_at(&scene, entries[i].path, entries[i].pos, rot, entries[i].scale, &gltf_draw_template_count))
        {
            printf("Failed to load gltf: %s\n", entries[i].path);
            return 1;
        }

        printf("Loaded: %s at (%.2f %.2f %.2f)\n", entries[i].label, entries[i].pos[0], entries[i].pos[1], entries[i].pos[2]);
    }

    uint32_t     material_count = (uint32_t)arrlen(scene.materials);
    MaterialGpu* materials_gpu  = (MaterialGpu*)malloc(sizeof(MaterialGpu) * material_count);
    if(!materials_gpu)
    {
        printf("Failed to allocate material buffer\n");
        return 1;
    }

    for(uint32_t i = 0; i < material_count; i++)
    {
        Material*    src = &scene.materials[i];
        MaterialGpu* dst = &materials_gpu[i];
        memset(dst, 0, sizeof(*dst));

        if(src->albedoTexture > 0)
            dst->textures[0] = (i & 1u) ? checker_slot : gradient_slot;
        else
            dst->textures[0] = 0;

        dst->textures[1] = 0;
        dst->textures[2] = 0;
        dst->textures[3] = 0;

        memcpy(dst->diffuseFactor, src->diffuseFactor, sizeof(dst->diffuseFactor));
        memcpy(dst->specularFactor, src->specularFactor, sizeof(dst->specularFactor));

        dst->emissiveFactor[0] = src->emissiveFactor[0];
        dst->emissiveFactor[1] = src->emissiveFactor[1];
        dst->emissiveFactor[2] = src->emissiveFactor[2];
        dst->emissiveFactor[3] = 0.0f;
    }

    VkDeviceSize material_bytes = (VkDeviceSize)material_count * sizeof(MaterialGpu);
    res_create_buffer(&allocator, material_bytes, VK_BUFFER_USAGE_2_STORAGE_BUFFER_BIT | VK_BUFFER_USAGE_2_TRANSFER_DST_BIT,
                      VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE, 0, 0, &material_buffer);
    upload_to_gpu_buffer(&allocator, qf.graphics_queue, upload_pool, material_buffer.buffer, 0, materials_gpu, material_bytes);
    free(materials_gpu);


    uint32_t     draw_count      = (uint32_t)arrlen(scene.draws);
    MeshDrawGpu* draws_cpu       = malloc(sizeof(MeshDrawGpu) * draw_count);
    Buffer       draw_cmd_buffer = {0};
    Buffer       draws_buffer    = {0};
    Buffer       indirect_buffer = {0};
    printf("scene meshes=%u vertices=%u indices=%u\n", (uint32_t)arrlen(scene.geometry.meshes),
           (uint32_t)arrlen(scene.geometry.vertices), (uint32_t)arrlen(scene.geometry.indices));
    GpuMeshBuffers gpu_scene = {0};

    VkDeviceSize vb_size = (VkDeviceSize)arrlen(scene.geometry.vertices) * sizeof(VertexPacked);
    VkDeviceSize ib_size = (VkDeviceSize)arrlen(scene.geometry.indices) * sizeof(uint32_t);

    res_create_buffer(&allocator, vb_size,
                      VK_BUFFER_USAGE_2_VERTEX_BUFFER_BIT | VK_BUFFER_USAGE_2_STORAGE_BUFFER_BIT | VK_BUFFER_USAGE_2_TRANSFER_DST_BIT,
                      VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE, 0, 0, &gpu_scene.vertex);

    res_create_buffer(&allocator, ib_size, VK_BUFFER_USAGE_2_INDEX_BUFFER_BIT | VK_BUFFER_USAGE_2_TRANSFER_DST_BIT,
                      VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE, 0, 0, &gpu_scene.index);

    // Upload data
    upload_to_gpu_buffer(&allocator, qf.graphics_queue, upload_pool, gpu_scene.vertex.buffer, 0, scene.geometry.vertices, vb_size);

    upload_to_gpu_buffer(&allocator, qf.graphics_queue, upload_pool, gpu_scene.index.buffer, 0, scene.geometry.indices, ib_size);

    gpu_scene.vertex_count = (uint32_t)arrlen(scene.geometry.vertices);
    gpu_scene.index_count  = (uint32_t)arrlen(scene.geometry.indices);


    if(arrlen(scene.geometry.meshes) == 0)
    {
        printf("Scene has no meshes\n");
        return 1;
    }

    uint32_t mesh_count = (uint32_t)arrlen(scene.geometry.meshes);
    MeshGpu* meshes_gpu = (MeshGpu*)malloc(sizeof(MeshGpu) * mesh_count);
    if(!meshes_gpu)
    {
        printf("Failed to allocate mesh GPU data\n");
        return 2;
    }

    for(uint32_t i = 0; i < mesh_count; i++)
    {
        Mesh*    src = &scene.geometry.meshes[i];
        MeshGpu* dst = &meshes_gpu[i];
        memset(dst, 0, sizeof(*dst));

        dst->center_radius[0] = src->center[0];
        dst->center_radius[1] = src->center[1];
        dst->center_radius[2] = src->center[2];
        dst->center_radius[3] = src->radius;

        dst->vertexOffset = src->vertexOffset;
        dst->vertexCount  = src->vertexCount;
        dst->lodCount     = src->lodCount;

        for(uint32_t li = 0; li < src->lodCount && li < SCENE_MAX_LODS; li++)
        {
            dst->lods[li].indexOffset = src->lods[li].indexOffset;
            dst->lods[li].indexCount  = src->lods[li].indexCount;
            dst->lods[li].error       = src->lods[li].error;
            dst->lods[li].pad         = 0.0f;
        }
    }

    VkDeviceSize mesh_bytes = (VkDeviceSize)mesh_count * sizeof(MeshGpu);
    res_create_buffer(&allocator, mesh_bytes, VK_BUFFER_USAGE_2_STORAGE_BUFFER_BIT | VK_BUFFER_USAGE_2_TRANSFER_DST_BIT,
                      VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE, 0, 0, &mesh_buffer);
    upload_to_gpu_buffer(&allocator, qf.graphics_queue, upload_pool, mesh_buffer.buffer, 0, meshes_gpu, mesh_bytes);
    free(meshes_gpu);

    res_create_buffer(&allocator, sizeof(uint32_t),
                      VK_BUFFER_USAGE_2_STORAGE_BUFFER_BIT | VK_BUFFER_USAGE_2_INDIRECT_BUFFER_BIT | VK_BUFFER_USAGE_2_TRANSFER_DST_BIT,
                      VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE, 0, 0, &draw_count_buffer);

    for(uint32_t i = 0; i < draw_count; i++)
    {
        MeshDraw* src = &scene.draws[i];

        draws_cpu[i].position_scale[0] = src->position[0];
        draws_cpu[i].position_scale[1] = src->position[1];
        draws_cpu[i].position_scale[2] = src->position[2];
        draws_cpu[i].position_scale[3] = src->scale;

        draws_cpu[i].orientation[0] = src->orientation[0];
        draws_cpu[i].orientation[1] = src->orientation[1];
        draws_cpu[i].orientation[2] = src->orientation[2];
        draws_cpu[i].orientation[3] = src->orientation[3];

        draws_cpu[i].meshIndex     = src->meshIndex;
        draws_cpu[i].postPass      = src->postPass;
        draws_cpu[i].materialIndex = src->materialIndex;
        draws_cpu[i].pad           = 0;
    }


    VkDeviceSize draw_cmd_bytes = (VkDeviceSize)draw_count * sizeof(MeshDrawCommand);
    VkDeviceSize draws_bytes    = (VkDeviceSize)draw_count * sizeof(MeshDrawGpu);

    res_create_buffer(&allocator, draw_cmd_bytes, VK_BUFFER_USAGE_2_STORAGE_BUFFER_BIT | VK_BUFFER_USAGE_2_TRANSFER_DST_BIT,
                      VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE, 0, 0, &draw_cmd_buffer);
    res_create_buffer(&allocator, draws_bytes, VK_BUFFER_USAGE_2_STORAGE_BUFFER_BIT | VK_BUFFER_USAGE_2_TRANSFER_DST_BIT,
                      VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE, 0, 0, &draws_buffer);
    res_create_buffer(&allocator, (VkDeviceSize)draw_count * sizeof(VkDrawIndexedIndirectCommand),
                      VK_BUFFER_USAGE_2_INDIRECT_BUFFER_BIT | VK_BUFFER_USAGE_2_STORAGE_BUFFER_BIT | VK_BUFFER_USAGE_2_TRANSFER_DST_BIT,
                      VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE, 0, 0, &indirect_buffer);
    MeshDrawCommand* init_cmds = malloc(draw_count * sizeof(MeshDrawCommand));
    for(uint32_t i = 0; i < draw_count; i++)
        init_cmds[i].drawId = i;

    upload_to_gpu_buffer(&allocator, qf.graphics_queue, upload_pool, draw_cmd_buffer.buffer, 0, init_cmds,
                         draw_count * sizeof(MeshDrawCommand));

    free(init_cmds);


    upload_to_gpu_buffer(&allocator, qf.graphics_queue, upload_pool, draws_buffer.buffer, 0, draws_cpu, draws_bytes);

    free(draws_cpu);

    DescriptorWriter w;
    desc_writer_begin(&w);

    desc_writer_write_buffer(&w, VK_NULL_HANDLE, 0, VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER, raymarch_ubo.buffer, 0, sizeof(RaymarchUBO));
    desc_writer_write_buffer(&w, VK_NULL_HANDLE, 0, VK_DESCRIPTOR_TYPE_STORAGE_BUFFER, draw_cmd_buffer.buffer, 0, draw_cmd_bytes);
    desc_writer_write_buffer(&w, VK_NULL_HANDLE, 1, VK_DESCRIPTOR_TYPE_STORAGE_BUFFER, draws_buffer.buffer, 0, draws_bytes);
    desc_writer_write_buffer(&w, VK_NULL_HANDLE, 2, VK_DESCRIPTOR_TYPE_STORAGE_BUFFER, gpu_scene.vertex.buffer, 0, vb_size);
    desc_writer_write_buffer(&w, VK_NULL_HANDLE, 3, VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER, global_ubo_buf.buffer, 0, sizeof(GlobalUBO));
    desc_writer_write_buffer(&w, VK_NULL_HANDLE, 4, VK_DESCRIPTOR_TYPE_STORAGE_BUFFER, material_buffer.buffer, 0, material_bytes);
    VK_CHECK(descriptor_build_set(&persistent_desc, &desc_cache, &set0_layout_info, &w, &set0));

    VkDescriptorSetLayoutBinding cull_bindings[6] = {
        {
            .binding         = 0,
            .descriptorType  = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER,
            .descriptorCount = 1,
            .stageFlags      = VK_SHADER_STAGE_COMPUTE_BIT,
        },
        {
            .binding         = 1,
            .descriptorType  = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,
            .descriptorCount = 1,
            .stageFlags      = VK_SHADER_STAGE_COMPUTE_BIT,
        },
        {
            .binding         = 2,
            .descriptorType  = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,
            .descriptorCount = 1,
            .stageFlags      = VK_SHADER_STAGE_COMPUTE_BIT,
        },
        {
            .binding         = 3,
            .descriptorType  = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,
            .descriptorCount = 1,
            .stageFlags      = VK_SHADER_STAGE_COMPUTE_BIT,
        },
        {
            .binding         = 4,
            .descriptorType  = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,
            .descriptorCount = 1,
            .stageFlags      = VK_SHADER_STAGE_COMPUTE_BIT,
        },
        {
            .binding         = 5,
            .descriptorType  = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,
            .descriptorCount = 1,
            .stageFlags      = VK_SHADER_STAGE_COMPUTE_BIT,
        },
    };

    VkDescriptorSetLayoutCreateInfo cull_layout_info = {
        .sType        = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO,
        .bindingCount = 6,
        .pBindings    = cull_bindings,
    };

    VkDescriptorSetLayout cull_set_layout = get_or_create_set_layout(&desc_cache, cull_bindings, 6, 0, NULL);
    (void)cull_set_layout;
    VkDescriptorSet cull_set = VK_NULL_HANDLE;

    desc_writer_begin(&w);
    desc_writer_write_buffer(&w, VK_NULL_HANDLE, 0, VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER, cull_data_buffer.buffer, 0,
                             sizeof(CullDataGpu));
    desc_writer_write_buffer(&w, VK_NULL_HANDLE, 1, VK_DESCRIPTOR_TYPE_STORAGE_BUFFER, draws_buffer.buffer, 0, draws_bytes);
    desc_writer_write_buffer(&w, VK_NULL_HANDLE, 2, VK_DESCRIPTOR_TYPE_STORAGE_BUFFER, mesh_buffer.buffer, 0, mesh_bytes);
    desc_writer_write_buffer(&w, VK_NULL_HANDLE, 3, VK_DESCRIPTOR_TYPE_STORAGE_BUFFER, draw_cmd_buffer.buffer, 0, draw_cmd_bytes);
    desc_writer_write_buffer(&w, VK_NULL_HANDLE, 4, VK_DESCRIPTOR_TYPE_STORAGE_BUFFER, indirect_buffer.buffer, 0,
                             (VkDeviceSize)draw_count * sizeof(VkDrawIndexedIndirectCommand));
    desc_writer_write_buffer(&w, VK_NULL_HANDLE, 5, VK_DESCRIPTOR_TYPE_STORAGE_BUFFER, draw_count_buffer.buffer, 0, sizeof(uint32_t));
    VK_CHECK(descriptor_build_set(&persistent_desc, &desc_cache, &cull_layout_info, &w, &cull_set));


    Camera cam = {0};
    camera_init(&cam);

    glfwSetInputMode(window, GLFW_CURSOR, GLFW_CURSOR_DISABLED);

    double last_mx = 0.0, last_my = 0.0;
    glfwGetCursorPos(window, &last_mx, &last_my);


    const float    lod_target  = 1.0f;  // max screen-space error in pixels
    const uint32_t lod_enabled = 1;

    while(!glfwWindowShouldClose(window))
    {
        glfwPollEvents();


        double mx, my;
        glfwGetCursorPos(window, &mx, &my);

        float dx = (float)(mx - last_mx);
        float dy = (float)(my - last_my);

        last_mx = mx;
        last_my = my;

        camera_apply_mouse(&cam, dx, dy);
        RaymarchUBO u = {.resolution = {(float)swap.extent.width, (float)swap.extent.height}, .time = (float)glfwGetTime()};
        memcpy(raymarch_ubo.mapping, &u, sizeof(u));


        float dt = 1.0f / 60.0f;  // replace with real delta time later
        camera_update_keyboard(&cam, window, dt);

        GlobalUBO ubo    = {0};
        float     aspect = (float)swap.extent.width / (float)swap.extent.height;
        build_global_ubo(&ubo, &cam, aspect);

        memcpy(global_ubo_buf.mapping, &ubo, sizeof(ubo));

        CullDataGpu cull = {0};
        glm_mat4_copy(ubo.view, cull.view);
        float tan_half_y = tanf(cam.fov_y * 0.5f);
        float tan_half_x = tan_half_y * aspect;
        cull.frustum[0]  = 1.0f;
        cull.frustum[1]  = tan_half_x;
        cull.frustum[2]  = 1.0f;
        cull.frustum[3]  = tan_half_y;
        cull.params[0]   = cam.znear;
        cull.params[1]   = cam.zfar;
        cull.params[2]   = lod_target;
        cull.params[3]   = (float)swap.extent.height;
        cull.counts[0]   = draw_count;
        cull.counts[1]   = lod_enabled;

        memcpy(cull_data_buffer.mapping, &cull, sizeof(cull));
        int w = 0, h = 0;
        glfwGetFramebufferSize(window, &w, &h);

        if(w == 0 || h == 0)
        {
            continue;
        }

        if(g_framebuffer_resized || w != (int)swap.extent.width || h != (int)swap.extent.height)
        {
            vkDeviceWaitIdle(device);
            vk_swapchain_recreate(device, gpu, &swap, w, h, qf.graphics_queue, upload_pool);
            destroy_depth_target(&allocator, &depth);
            create_depth_target(&allocator, &depth, swap.extent.width, swap.extent.height, depth_format);
            vk_debug_text_on_swapchain_recreated(&dbg, &persistent_desc, &desc_cache, &swap);
            g_framebuffer_resized = false;
            continue;
        }

        bool recreate = false;
        vkWaitForFences(device, 1, &frame_sync[current_frame].in_flight_fence, VK_TRUE, UINT64_MAX);


        {
            float frame_us = 0.0f, gfx_us = 0.0f, text_us = 0.0f;

            gpu_prof_get_us(&prof[current_frame], "frame", &frame_us);
            gpu_prof_get_us(&prof[current_frame], "gfx", &gfx_us);
            gpu_prof_get_us(&prof[current_frame], "debug_text", &text_us);

            stats[current_frame] = (GpuStats){
                .frame_us = frame_us,
                .gfx_us   = gfx_us,
                .text_us  = text_us,
            };
        }
        GpuProfiler* P = &prof[current_frame];
        vkResetFences(device, 1, &frame_sync[current_frame].in_flight_fence);
        /* reset EVERYTHING allocated for this frame */
        vkResetCommandPool(device, cmd_pools[current_frame], 0);
        // Acquire image
        if(!vk_swapchain_acquire(device, &swap, frame_sync[current_frame].image_available_semaphore, VK_NULL_HANDLE,
                                 UINT64_MAX, &recreate))
        {
            if(recreate)
            {
                vk_swapchain_recreate(device, gpu, &swap, w, h, qf.graphics_queue, upload_pool);
                destroy_depth_target(&allocator, &depth);
                create_depth_target(&allocator, &depth, swap.extent.width, swap.extent.height, depth_format);
                vk_debug_text_on_swapchain_recreated(&dbg, &persistent_desc, &desc_cache, &swap);
                continue;
            }
        }
        image_index = swap.current_image;

        // -------------------------------------------------------------
        // RENDER HERE using swap.images[image_index] via your FB/pipeline
        // -------------------------------------------------------------
        VkCommandBuffer cmd = cmd_buffers[current_frame];
        vk_cmd_begin(cmd, true);
        gpu_prof_begin_frame(cmd, P);
        /* transition for rendering target */

        // Transition swapchain image for rendering
        IMAGE_BARRIER_IMMEDIATE(cmd, swap.images[image_index], VK_IMAGE_LAYOUT_PRESENT_SRC_KHR, VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL);

        // Transition depth image for depth attachment usage
        IMAGE_BARRIER_IMMEDIATE(cmd, depth.image[current_frame], depth.layout[current_frame],
                                VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_OPTIMAL, .aspect = VK_IMAGE_ASPECT_DEPTH_BIT);
        depth.layout[current_frame] = VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_OPTIMAL;

        VkRenderingAttachmentInfo color_attach = {.sType       = VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_INFO,
                                                  .imageView   = swap.image_views[image_index],
                                                  .imageLayout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL,
                                                  .loadOp      = VK_ATTACHMENT_LOAD_OP_CLEAR,
                                                  .storeOp     = VK_ATTACHMENT_STORE_OP_STORE,
                                                  .clearValue  = {.color = {.float32 = {0.05f, 0.05f, 0.08f, 1.0f}}}};
        VkRenderingAttachmentInfo depth_attach = {
            .sType       = VK_STRUCTURE_TYPE_RENDERING_ATTACHMENT_INFO,
            .imageView   = depth.view[current_frame],
            .imageLayout = VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_OPTIMAL,
            .loadOp      = VK_ATTACHMENT_LOAD_OP_CLEAR,
            .storeOp     = VK_ATTACHMENT_STORE_OP_STORE,
            .clearValue  = {.depthStencil = {0.0f, 0}},
        };


        VkRenderingInfo rendering = {.sType = VK_STRUCTURE_TYPE_RENDERING_INFO,
                                     .renderArea = {.offset = {0, 0}, .extent = {swap.extent.width, swap.extent.height}},
                                     .layerCount           = 1,
                                     .colorAttachmentCount = 1,
                                     .pColorAttachments    = &color_attach,
                                     .pDepthAttachment     = &depth_attach};
        GPU_SCOPE(cmd, P, "cull", VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT)
        {
            vkCmdFillBuffer(cmd, draw_count_buffer.buffer, 0, sizeof(uint32_t), 0);
            BUFFER_BARRIER_IMMEDIATE(cmd, draw_count_buffer.buffer, VK_PIPELINE_STAGE_2_TRANSFER_BIT,
                                     VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT);

            vkCmdBindPipeline(cmd, VK_PIPELINE_BIND_POINT_COMPUTE, cull_pipeline);
            vkCmdBindDescriptorSets(cmd, VK_PIPELINE_BIND_POINT_COMPUTE, cull_layout, 0, 1, &cull_set, 0, NULL);

            uint32_t group_count = (draw_count + 63u) / 64u;
            vkCmdDispatch(cmd, group_count, 1, 1);

            BUFFER_BARRIER_IMMEDIATE(cmd, draw_cmd_buffer.buffer, VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT,
                                     VK_PIPELINE_STAGE_2_VERTEX_SHADER_BIT);
            BUFFER_BARRIER_IMMEDIATE(cmd, indirect_buffer.buffer, VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT,
                                     VK_PIPELINE_STAGE_2_DRAW_INDIRECT_BIT);
            BUFFER_BARRIER_IMMEDIATE(cmd, draw_count_buffer.buffer, VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT,
                                     VK_PIPELINE_STAGE_2_DRAW_INDIRECT_BIT);
        }

        GPU_SCOPE(cmd, P, "gfx", VK_PIPELINE_STAGE_2_COLOR_ATTACHMENT_OUTPUT_BIT)
        {
            vkCmdBeginRendering(cmd, &rendering);
            vk_cmd_set_viewport_scissor(cmd, swap.extent);


            VkDescriptorSet sets[2] = {set0, bindless.set};

            vkCmdBindDescriptorSets(cmd, VK_PIPELINE_BIND_POINT_GRAPHICS, pipeline_layout, 0, 2, sets, 0, NULL);
            vkCmdBindPipeline(cmd, VK_PIPELINE_BIND_POINT_GRAPHICS, pipeline);


            vkCmdBindIndexBuffer(cmd, gpu_scene.index.buffer, 0, VK_INDEX_TYPE_UINT32);

            vkCmdDrawIndexedIndirectCount(cmd, indirect_buffer.buffer, 0, draw_count_buffer.buffer, 0, draw_count,
                                          sizeof(VkDrawIndexedIndirectCommand));
            // ---- Draw fullscreen raymarch on top ----
            vkCmdBindPipeline(cmd, VK_PIPELINE_BIND_POINT_GRAPHICS, raymarch_pipeline);
            vkCmdBindDescriptorSets(cmd, VK_PIPELINE_BIND_POINT_GRAPHICS, raymarch_layout, 0, 1, &raySet, 0, NULL);

            // no vertex buffers, fullscreen triangle
            vkCmdDraw(cmd, 3, 1, 0, 0);

            vkCmdEndRendering(cmd);
        }


        GPU_SCOPE(cmd, P, "debug_text", VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT)
        {
            vk_debug_text_begin_frame(&dbg);

            GpuStats s = stats[current_frame];


            vk_debug_text_printf(&dbg, 1, 20, 2, pack_rgba8(255, 255, 0, 255), "GPU frame: %.2f us (%.2f ms)",
                                 s.frame_us, s.frame_us / 1000.0f);

            vk_debug_text_printf(&dbg, 7, 2, 2, pack_rgba8(0, 255, 0, 255), "gfx: %.2f us | text: %.2f us", s.gfx_us, s.text_us);

            vk_debug_text_flush(&dbg, cmd, swap.images[image_index], image_index);
        }


        gpu_prof_end_frame(cmd, P);
        IMAGE_BARRIER_IMMEDIATE(cmd, swap.images[image_index], VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL, VK_IMAGE_LAYOUT_PRESENT_SRC_KHR);


        vk_cmd_end(cmd);
        VkSemaphoreSubmitInfo wait_info   = {.sType     = VK_STRUCTURE_TYPE_SEMAPHORE_SUBMIT_INFO,
                                             .semaphore = frame_sync[current_frame].image_available_semaphore,
                                             .value     = 0,
                                             .stageMask = VK_PIPELINE_STAGE_2_COLOR_ATTACHMENT_OUTPUT_BIT};
        VkSemaphoreSubmitInfo signal_info = {
            .sType     = VK_STRUCTURE_TYPE_SEMAPHORE_SUBMIT_INFO,
            .semaphore = swap.render_finished[image_index],
            .value     = 0,
            .stageMask = VK_PIPELINE_STAGE_2_ALL_GRAPHICS_BIT,
        };

        VkCommandBufferSubmitInfo cmdInfo = {.sType         = VK_STRUCTURE_TYPE_COMMAND_BUFFER_SUBMIT_INFO_KHR,
                                             .pNext         = NULL,
                                             .commandBuffer = cmd_buffers[current_frame],
                                             .deviceMask    = 0};

        VkSubmitInfo2 submit = {.sType                    = VK_STRUCTURE_TYPE_SUBMIT_INFO_2,
                                .waitSemaphoreInfoCount   = 1,
                                .pWaitSemaphoreInfos      = &wait_info,
                                .commandBufferInfoCount   = 1,
                                .pCommandBufferInfos      = &cmdInfo,
                                .signalSemaphoreInfoCount = 1,
                                .pSignalSemaphoreInfos    = &signal_info


        };

        VK_CHECK(vkQueueSubmit2(qf.graphics_queue, 1, &submit, frame_sync[current_frame].in_flight_fence));
        if(!vk_swapchain_present(qf.present_queue, &swap, &swap.render_finished[swap.current_image], 1, &recreate))
        {
            if(recreate)
            {

                vk_swapchain_recreate(device, gpu, &swap, w, h, qf.graphics_queue, upload_pool);


                {
                    destroy_depth_target(&allocator, &depth);
                    create_depth_target(&allocator, &depth, swap.extent.width, swap.extent.height, depth_format);
                }
                vk_debug_text_on_swapchain_recreated(&dbg, &persistent_desc, &desc_cache, &swap);

                continue;
            }
        }

        current_frame = (current_frame + 1) % MAX_FRAME_IN_FLIGHT;
    }

    vkDeviceWaitIdle(device);


    vk_debug_text_destroy(&dbg);
    descriptor_allocator_destroy(&persistent_desc);
    descriptor_allocator_destroy(&bindless_desc);
    descriptor_layout_cache_destroy(&desc_cache);
    pipeline_layout_cache_destroy(device, &pipe_cache);

    bindless_textures_destroy(&bindless, &allocator, device);

    res_destroy_buffer(&allocator, &global_ubo_buf);
    res_destroy_buffer(&allocator, &cull_data_buffer);
    res_destroy_buffer(&allocator, &material_buffer);
    res_destroy_buffer(&allocator, &draw_cmd_buffer);
    res_destroy_buffer(&allocator, &draws_buffer);
    res_destroy_buffer(&allocator, &indirect_buffer);
    res_destroy_buffer(&allocator, &draw_count_buffer);
    res_destroy_buffer(&allocator, &mesh_buffer);
    res_destroy_buffer(&allocator, &gpu_scene.index);
    res_destroy_buffer(&allocator, &gpu_scene.vertex);

    destroy_depth_target(&allocator, &depth);

    vk_swapchain_destroy(device, &swap);

    res_deinit(&allocator);  // <- allocator dies LAST

    for(u32 i = 0; i < MAX_FRAME_IN_FLIGHT; i++)
    {
        gpu_prof_destroy(&prof[i]);
    }

    for(u32 i = 0; i < MAX_FRAME_IN_FLIGHT; i++)
    {
        vkDestroyCommandPool(device, cmd_pools[i], NULL);
    }


    for(u32 i = 0; i < MAX_FRAME_IN_FLIGHT; i++)
    {
        if(frame_sync[i].image_available_semaphore)
            vkDestroySemaphore(device, frame_sync[i].image_available_semaphore, NULL);

        if(frame_sync[i].in_flight_fence)
            vkDestroyFence(device, frame_sync[i].in_flight_fence, NULL);
    }

    if(upload_pool)
        vkDestroyCommandPool(device, upload_pool, NULL);
    vkDestroyPipeline(device, pipeline, NULL);
    vkDestroyPipeline(device, cull_pipeline, NULL);
    vkDestroySurfaceKHR(ctx.instance, surface, NULL);
    vkDestroyDevice(device, NULL);

    vkDestroyDebugUtilsMessengerEXT(ctx.instance, ctx.debug_utils, NULL);
    vkDestroyInstance(ctx.instance, NULL);

    glfwDestroyWindow(window);
    glfwTerminate();

    return 0;
}
